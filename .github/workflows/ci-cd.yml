name: TrustworthyCodeLLM CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: "3.9"
  NODE_VERSION: "18"

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, "3.10", "3.11"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
    
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: Lint with black
      run: |
        black --check --diff src/ tests/ examples/
    
    - name: Sort imports with isort
      run: |
        isort --check-only --diff src/ tests/ examples/
    
    - name: Type check with mypy
      run: |
        mypy src/ --ignore-missing-imports
    
    - name: Security check with bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
    
    - name: Run tests
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=html
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: Run experimental validation
      run: |
        python experiments/experimental_validation.py --quick
    
    - name: Test CLI
      run: |
        python cli.py version
        echo "def hello(): return 'world'" | python cli.py evaluate --code -

  security:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  build-dashboard:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Test dashboard startup
      run: |
        timeout 30s python -m uvicorn web_dashboard.app:app --host 0.0.0.0 --port 8000 &
        sleep 10
        curl -f http://localhost:8000/health || exit 1

  reproducibility:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .
    
    - name: Run reproducibility validation
      run: |
        python reproduce_results.py --quick
    
    - name: Generate reproducibility report
      run: |
        python -c "
        import json
        from pathlib import Path
        
        # Create reproducibility report
        report = {
          'timestamp': '$(date -u +%Y-%m-%dT%H:%M:%SZ)',
          'commit': '${{ github.sha }}',
          'status': 'validated',
          'components': [
            'framework', 'evaluators', 'dataset', 
            'experiments', 'dashboard', 'cli'
          ]
        }
        
        Path('reproducibility-report.json').write_text(json.dumps(report, indent=2))
        "
    
    - name: Upload reproducibility artifacts
      uses: actions/upload-artifact@v3
      with:
        name: reproducibility-report
        path: |
          reproducibility-report.json
          results/
          logs/

  release:
    runs-on: ubuntu-latest
    needs: [test, security, build-dashboard, reproducibility]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Build package
      run: |
        python -m build
    
    - name: Create GitHub Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: v${{ github.run_number }}
        release_name: TrustworthyCodeLLM v${{ github.run_number }}
        body: |
          ## What's Changed
          
          - Enhanced multi-modal evaluation framework
          - Improved dataset generation and validation
          - Interactive web dashboard
          - Comprehensive reproducibility pipeline
          
          ## Validation Results
          
          ✅ All tests passed
          ✅ Security scan clean
          ✅ Reproducibility validated
          ✅ Dashboard functional
          
          ## Usage
          
          ```bash
          pip install trustworthy-code-llm-eval
          python cli.py evaluate --code "your_code_here"
          python cli.py dashboard
          ```
        draft: false
        prerelease: false

  notify:
    runs-on: ubuntu-latest
    needs: [test, security, build-dashboard, reproducibility]
    if: always()
    
    steps:
    - name: Notify on success
      if: ${{ needs.test.result == 'success' && needs.security.result == 'success' }}
      run: |
        echo "✅ All checks passed! TrustworthyCodeLLM is ready for deployment."
    
    - name: Notify on failure
      if: ${{ needs.test.result == 'failure' || needs.security.result == 'failure' }}
      run: |
        echo "❌ Some checks failed. Please review the logs and fix issues."
        exit 1
